{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasuil/006947/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkGWmXoy91ps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from numpy.testing import assert_allclose\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import LSTM, Dropout, Dense\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "vec_size = 100\n",
        "n_units = 10\n",
        "\n",
        "x_train = np.random.rand(500, 10, vec_size)\n",
        "y_train = np.random.rand(500, vec_size)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(n_units, input_shape=(None, vec_size), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(n_units, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(n_units))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(vec_size, activation='linear'))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# define the checkpoint\n",
        "filepath = \"model.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38fhOr0Z_6tf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "3ced5317-0372-4781-bc4d-9f6311b74df6"
      },
      "source": [
        "# fit the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=50, callbacks=callbacks_list)\n",
        "\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.3239\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.32392, saving model to model.h5\n",
            "Epoch 2/5\n",
            "500/500 [==============================] - 0s 437us/step - loss: 0.2981\n",
            "\n",
            "Epoch 00002: loss improved from 0.32392 to 0.29814, saving model to model.h5\n",
            "Epoch 3/5\n",
            "500/500 [==============================] - 0s 458us/step - loss: 0.2619\n",
            "\n",
            "Epoch 00003: loss improved from 0.29814 to 0.26188, saving model to model.h5\n",
            "Epoch 4/5\n",
            "500/500 [==============================] - 0s 438us/step - loss: 0.2152\n",
            "\n",
            "Epoch 00004: loss improved from 0.26188 to 0.21522, saving model to model.h5\n",
            "Epoch 5/5\n",
            "500/500 [==============================] - 0s 428us/step - loss: 0.1714\n",
            "\n",
            "Epoch 00005: loss improved from 0.21522 to 0.17137, saving model to model.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7130e81ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N36G-Oc0_9w-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "outputId": "fda1a23e-7c92-4640-871a-f9f3283be564"
      },
      "source": [
        "# load the model\n",
        "new_model = load_model(\"model.h5\")\n",
        "assert_allclose(model.predict(x_train),\n",
        "                new_model.predict(x_train),\n",
        "                1e-5)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-66a1c8659381>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m assert_allclose(model.predict(x_train),\n\u001b[1;32m      3\u001b[0m                 \u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                 1e-5)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36massert_allclose\u001b[0;34m(actual, desired, rtol, atol, equal_nan, err_msg, verbose)\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Not equal to tolerance rtol=%g, atol=%g'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m     assert_array_compare(compare, actual, desired, err_msg=str(err_msg),\n\u001b[0;32m-> 1515\u001b[0;31m                          verbose=verbose, header=header, equal_nan=equal_nan)\n\u001b[0m\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)\u001b[0m\n\u001b[1;32m    839\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m                                 names=('x', 'y'), precision=precision)\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=1e-05, atol=0\n\nMismatch: 100%\nMax absolute difference: 0.5396539\nMax relative difference: 1.0945381\n x: array([[ 6.574860e-03, -3.988263e-02, -1.494167e-03, ...,  2.509399e-03,\n        -1.031995e-02, -2.425834e-02],\n       [-5.679555e-05, -2.361963e-02, -6.350890e-03, ..., -6.129675e-03,...\n y: array([[0.466716, 0.49091 , 0.46123 , ..., 0.467049, 0.477247, 0.49271 ],\n       [0.466614, 0.490061, 0.460834, ..., 0.465735, 0.476735, 0.491872],\n       [0.46605 , 0.490225, 0.460361, ..., 0.465721, 0.4765  , 0.491858],..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LixyoFQh__-V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "67ec758a-2de8-4556-b51e-70bc0fc751ee"
      },
      "source": [
        "\n",
        "# fit the model\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "new_model.fit(x_train, y_train, epochs=5, batch_size=50, callbacks=callbacks_list)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "500/500 [==============================] - 0s 465us/step - loss: 0.1023\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.10235, saving model to model.h5\n",
            "Epoch 2/5\n",
            "500/500 [==============================] - 0s 432us/step - loss: 0.0994\n",
            "\n",
            "Epoch 00002: loss improved from 0.10235 to 0.09939, saving model to model.h5\n",
            "Epoch 3/5\n",
            "500/500 [==============================] - 0s 447us/step - loss: 0.0993\n",
            "\n",
            "Epoch 00003: loss improved from 0.09939 to 0.09930, saving model to model.h5\n",
            "Epoch 4/5\n",
            "500/500 [==============================] - 0s 449us/step - loss: 0.0984\n",
            "\n",
            "Epoch 00004: loss improved from 0.09930 to 0.09837, saving model to model.h5\n",
            "Epoch 5/5\n",
            "500/500 [==============================] - 0s 443us/step - loss: 0.0991\n",
            "\n",
            "Epoch 00005: loss did not improve from 0.09837\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f71401ba438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    }
  ]
}